{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:42:51.336181Z",
     "start_time": "2024-08-20T12:42:51.002684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import wandb\n",
    "from rliable import library as rly\n",
    "from rliable import metrics\n",
    "from rliable import plot_utils\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils import *"
   ],
   "id": "6620ecb5fed9d04c",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:42:51.358034Z",
     "start_time": "2024-08-20T12:42:51.355027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.rcParams[\"legend.title_fontsize\"] = \"large\"\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "matplotlib.rc(\"xtick\", labelsize=48)\n",
    "matplotlib.rc(\"ytick\", labelsize=48)"
   ],
   "id": "9e8352df8348bfd6",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:42:53.249503Z",
     "start_time": "2024-08-20T12:42:51.893667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the wandb API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Define your project and entity (replace with your specific values)\n",
    "entity = \"cl-probing\"  # e.g., your username or team name\n",
    "project = \"energy-functions-only\"  # e.g., your project name\n",
    "figures_path = f\"./figures/{project}\"\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "take_x_seeds = 5\n",
    "window_size = 5\n",
    "use_se = True"
   ],
   "id": "990d17257b0c83a7",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:42:53.330516Z",
     "start_time": "2024-08-20T12:42:53.300076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exp_names = [\n",
    "    \"ant_l_symmetric_infonce_ef_l1\",\n",
    "    \"ant_l_symmetric_infonce_ef_l2\",\n",
    "    \"ant_l_symmetric_infonce_ef_l2_no_sqrt\",\n",
    "    \"ant_l_symmetric_infonce_ef_dot\",\n",
    "    \"ant_l_symmetric_infonce_ef_cos\",\n",
    "]\n",
    "\n",
    "exp_names_mapping = {\n",
    "    \"ant_l_symmetric_infonce_ef_l1\": \"L1\",\n",
    "    \"ant_l_symmetric_infonce_ef_l2\": \"L2\",\n",
    "    \"ant_l_symmetric_infonce_ef_l2_no_sqrt\": \"L2 w/o sqrt\",\n",
    "    \"ant_l_symmetric_infonce_ef_dot\": \"Dot\",\n",
    "    \"ant_l_symmetric_infonce_ef_cos\": \"Cos\",\n",
    "}"
   ],
   "id": "74fec9a47bd2e728",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:42:53.403217Z",
     "start_time": "2024-08-20T12:42:53.361076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env_title_mapping = {\n",
    "    \"ant_ball\": \"Ant Soccer\",\n",
    "    \"ant\": \"Ant\",\n",
    "    \"ant_big_maze\": \"Ant Big Maze\",\n",
    "    \"ant_u_maze\": \"Ant U-Maze\",\n",
    "    \"pusher_hard\": \"Pusher\"\n",
    "}\n",
    "metric_to_metric_label_dict = {\n",
    "    \"eval/episode_success\": \"Time near goal\",\n",
    "    \"eval/episode_success_any\": \"Success rate\",\n",
    "}"
   ],
   "id": "75da98da4ff2f4a0",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Results for all envs",
   "id": "dd91a5cd2e33c161"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:42:53.494284Z",
     "start_time": "2024-08-20T12:42:53.434497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics_ = [\"eval/episode_success_any\", \"eval/episode_success\"]\n",
    "single_env=False\n"
   ],
   "id": "bb9f116ea5bad39f",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:42:53.885540Z",
     "start_time": "2024-08-20T12:42:53.524494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define filters for the run config (replace with your specific filters)\n",
    "filters = {\n",
    "    \"config.batch_size\": 256,  # example filter, modify as needed\n",
    "    \"config.exp_name\": {\"$in\": exp_names},\n",
    "    \"config.env_name\": {\"$in\": list(env_title_mapping.keys())},\n",
    "    \"state\": \"finished\",\n",
    "    \"config.num_envs\": 1024\n",
    "}\n",
    "\n",
    "# Fetch the runs from the API\n",
    "runs = api.runs(path=f\"{entity}/{project}\", filters=filters)"
   ],
   "id": "2e7a372bc13d8bc",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:42:54.354518Z",
     "start_time": "2024-08-20T12:42:53.917717Z"
    }
   },
   "cell_type": "code",
   "source": "len(runs)",
   "id": "b2403860832f01b9",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:43:05.752615Z",
     "start_time": "2024-08-20T12:42:54.404246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for metric in metrics_:\n",
    "    metric_label = metric_to_metric_label_dict[metric]\n",
    "    data = aggregate_data_from_wandb(\n",
    "        runs, metric, exp_names, exp_names_mapping, env_title_mapping, take_x_seeds, single_env\n",
    "    )\n",
    "    \n",
    "    # Smoothing\n",
    "    for key, item in data.items():\n",
    "        data[key] = np.apply_along_axis(moving_average_smoothing, axis=-1, arr=item, window_size=window_size) \n",
    "    \n",
    "    data_flattened = {key: np.mean(elem[:,:, -10:], axis=-1) for key, elem in data.items()}\n",
    "    \n",
    "    thresholds = np.linspace(0.0, 1, 41)\n",
    "    score_distributions, score_distributions_cis = rly.create_performance_profile(\n",
    "        data_flattened, thresholds\n",
    "    )\n",
    "    \n",
    "    # Plot Performance Profiles\n",
    "    # fig, ax = plt.subplots(ncols=1, figsize=(7, 5))\n",
    "    # plot_utils.plot_performance_profiles(\n",
    "    #     score_distributions,\n",
    "    #     thresholds,\n",
    "    #     performance_profile_cis=score_distributions_cis,\n",
    "    #     colors=dict(zip(list(data_flattened.keys()), sns.color_palette(\"colorblind\"))),\n",
    "    #     xlabel=rf\"{metric_label} $(\\tau)$\",\n",
    "    #     ylabel=rf\"Fraction of runs with success rate > $\\tau$\",\n",
    "    #     ax=ax,\n",
    "    #     legend=True,\n",
    "    #     legendsize=\"medium\",\n",
    "    #     grid_alpha=0.4, \n",
    "    #     figsize=(12,8),\n",
    "    #     # use_non_linear_scaling=True\n",
    "    # )\n",
    "    # plt.xlim((0, 0.7))\n",
    "    # plt.tight_layout()\n",
    "    # plt.ylabel(rf\"Fraction of runs with success rate > $\\tau$\", wrap=True)\n",
    "    # plt.savefig(os.path.join(figures_path, f\"{metric_label.replace(' ', '_')}_performance_profile_{single_env if single_env else 'all'}.pdf\"), bbox_inches=\"tight\")\n",
    "    \n",
    "    \n",
    "    # Sample efficiency curve\n",
    "    frames = np.arange(0, 55, 5)\n",
    "    frames[-1] -= 1\n",
    "    ale_frames_scores_dict = {algorithm: score[:, :, frames] for algorithm, score in data.items()}\n",
    "    iqm = lambda scores: np.array([metrics.aggregate_iqm(scores[..., frame]) for frame in range(scores.shape[-1])])\n",
    "    iqm_scores, iqm_cis = rly.get_interval_estimates(ale_frames_scores_dict, iqm, reps=2000)\n",
    "    \n",
    "    # Change to se\n",
    "    if use_se:\n",
    "        for key, elem in iqm_scores.items():\n",
    "            se = np.apply_along_axis(lambda x: x[1]-x[0], axis=0, arr=iqm_cis[key])/2/1.96 \n",
    "            iqm_cis[key] = np.concatenate(((elem-se)[None, :], (elem+se)[None,:]), axis=0)\n",
    "    \n",
    "    plot_utils.plot_sample_efficiency_curve(\n",
    "        frames + 1,\n",
    "        iqm_scores,\n",
    "        iqm_cis,\n",
    "        algorithms=list(data.keys()),\n",
    "        xlabel=r\"Number of environment steps (in millions)\",\n",
    "        ylabel=metric_label,\n",
    "        legend=True,\n",
    "        grid_alpha=0.4,\n",
    "        figsize=(8, 6),\n",
    "    )\n",
    "    plt.title(f\"{env_title_mapping[single_env] if single_env else ''}\", fontsize=\"xx-large\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_path, f\"{metric_label.replace(' ', '_')}_{single_env if single_env else 'all'}.pdf\"))\n",
    "    \n",
    "    \n",
    "    # Plot interval estimates    \n",
    "    aggregate_func = lambda x: np.array(\n",
    "    [\n",
    "        metrics.aggregate_iqm(x),\n",
    "    ]\n",
    "    )\n",
    "    aggregate_scores, aggregate_score_cis = rly.get_interval_estimates(\n",
    "        data_flattened, aggregate_func, reps=500\n",
    "    )\n",
    "    \n",
    "    # Change to se\n",
    "    if use_se:\n",
    "        for key, elem in aggregate_scores.items():\n",
    "            se = (aggregate_score_cis[key][1]-aggregate_score_cis[key][0])/2/1.96 \n",
    "            aggregate_score_cis[key] = np.concatenate(((elem-se)[None, :], (elem+se)[None,:]), axis=0)\n",
    "\n",
    "    fig, axes = plot_utils.plot_interval_estimates(\n",
    "        aggregate_scores,\n",
    "        aggregate_score_cis,\n",
    "        metric_names=[\"IQM\"],\n",
    "        algorithms=list(data.keys()),\n",
    "        xlabel=f\"{metric_label}\",\n",
    "        grid_alpha=0.4,\n",
    "        max_ticks=3,\n",
    "        subfigure_width=4,\n",
    "        xlabel_y_coordinate=-0.3,\n",
    "    )\n",
    "    plt.subplots_adjust(wspace=0.2, left=0.0)\n",
    "    # for ax in axes:\n",
    "    #     ax.set_xlim((0.4, 0.8))\n",
    "    \n",
    "    \n",
    "    plt.savefig(\n",
    "        os.path.join(figures_path, f\"{metric_label.replace(' ', '_')}_all_interval_estimate.pdf\"), bbox_inches=\"tight\"\n",
    "    )"
   ],
   "id": "a2c2413115e2a4b9",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Per env",
   "id": "d699de26f0370a7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:43:05.784209Z",
     "start_time": "2024-08-20T12:43:05.782211Z"
    }
   },
   "cell_type": "code",
   "source": "metrics_ = [\"eval/episode_success_any\", \"eval/episode_success\"]",
   "id": "e27701549850fb2c",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T12:43:22.944580Z",
     "start_time": "2024-08-20T12:43:05.833837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for env in list(env_title_mapping.keys()):\n",
    "    single_env = env\n",
    "\n",
    "    filters = {\n",
    "        \"config.batch_size\": 256,  # example filter, modify as needed\n",
    "        \"config.exp_name\": {\"$in\": exp_names},\n",
    "        \"config.env_name\": single_env,\n",
    "        \"state\": \"finished\",\n",
    "        \"config.num_envs\": 1024\n",
    "    }\n",
    "\n",
    "    # Fetch the runs from the API\n",
    "    runs = api.runs(path=f\"{entity}/{project}\", filters=filters)\n",
    "    print(f\"Len runs: {len(runs)}\")\n",
    "\n",
    "    for metric in metrics_:\n",
    "        metric_label = metric_to_metric_label_dict[metric]\n",
    "        data = aggregate_data_from_wandb(\n",
    "            runs, metric, exp_names, exp_names_mapping, env_title_mapping, take_x_seeds, single_env\n",
    "        )\n",
    "\n",
    "        # Smoothing\n",
    "        for key, item in data.items():\n",
    "            data[key] = np.apply_along_axis(moving_average_smoothing, axis=-1, arr=item, window_size=10)\n",
    "\n",
    "        # Sample efficiency curves\n",
    "        frames = np.arange(0, 55, 5)\n",
    "        frames[-1] -= 1\n",
    "        ale_frames_scores_dict = {algorithm: score[:, :, frames] for algorithm, score in data.items()}\n",
    "        iqm = lambda scores: np.array([metrics.aggregate_iqm(scores[..., frame]) for frame in range(scores.shape[-1])])\n",
    "        iqm_scores, iqm_cis = rly.get_interval_estimates(ale_frames_scores_dict, iqm, reps=2000)\n",
    "        \n",
    "        # Change to se\n",
    "        if use_se:\n",
    "            for key, elem in iqm_scores.items():\n",
    "                se = np.apply_along_axis(lambda x: x[1]-x[0], axis=0, arr=iqm_cis[key])/2/1.96 \n",
    "                iqm_cis[key] = np.concatenate(((elem-se)[None, :], (elem+se)[None,:]), axis=0)\n",
    "            \n",
    "        plot_utils.plot_sample_efficiency_curve(\n",
    "            frames + 1,\n",
    "            iqm_scores,\n",
    "            iqm_cis,\n",
    "            algorithms=list(data.keys()),\n",
    "            xlabel=r\"Number of environment steps (in millions)\",\n",
    "            ylabel=metric_label,\n",
    "            legend=True,\n",
    "            grid_alpha=0.4,\n",
    "            figsize=(8, 6),\n",
    "        )\n",
    "        plt.title(f\"{env_title_mapping[single_env] if single_env else ''}\", fontsize=\"xx-large\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(figures_path, f\"{metric_label.replace(' ', '_')}_{single_env if single_env else 'all'}.pdf\")\n",
    "        )"
   ],
   "id": "32556aa3c2831ae0",
   "execution_count": 11,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
